{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "############################################### Question 3.a #######################################################\n",
    "'''reading the data and changing the values of Male, Female and Infant to corresponding binary values'''\n",
    "def read_the_data():\n",
    "    linreg_data = []\n",
    "    with open('/linregdata') as file:\n",
    "        data = csv.reader(file, delimiter = ',')\n",
    "        for row in data:\n",
    "            linreg_data.append(row)\n",
    "    \n",
    "    return linreg_data\n",
    "\n",
    "def get_a_df_with_binary_values_corresponding_to_gender(linreg_data):\n",
    "    \n",
    "    \n",
    "    binary_values = [[1, 0, 0] if item[0] == 'F' \n",
    "                          else ([0, 1, 0] if item[0] == 'I' \n",
    "                                else ([0, 0, 1] if item[0] == 'M' \n",
    "                                      else (item[0]))) \n",
    "                                           for item in linreg_data]\n",
    "    \n",
    "    return pd.DataFrame(binary_values)\n",
    "\n",
    "\n",
    "\n",
    "def replace_gender_in_linreg_with_binary_values(binary_values, linreg_data):\n",
    "    \n",
    "    binary_values_df = pd.DataFrame(binary_values)\n",
    "    linreg_df = pd.DataFrame(linreg_data)\n",
    "    linreg_df.drop(0, axis = 1, inplace = True)\n",
    "    \n",
    "    for index in range(3):\n",
    "        linreg_df.insert(loc = index, column = index + 10, value = binary_values_df.iloc[:,index])\n",
    "    \n",
    "    linreg_df.columns = np.arange(0, len(linreg_df.columns))\n",
    "    return linreg_df\n",
    "\n",
    "\n",
    "######################################## Question 3.b ######################################################\n",
    "\n",
    "'''standardizing the data'''\n",
    "def get_the_convert_data_types_dict(no_of_columns):\n",
    "    convert_to = {}\n",
    "    \n",
    "    for i in range(3, no_of_columns):\n",
    "        convert_to[i] = np.float32\n",
    "        \n",
    "    return convert_to\n",
    "\n",
    "\n",
    "def convert_data_type_from_str_to_float(linreg_data):\n",
    "    \n",
    "    no_of_columns = np.shape(linreg_data)[1]\n",
    "    convert_data_types = get_the_convert_data_types_dict(no_of_columns)\n",
    "    linreg_data = linreg_data.astype(convert_data_types)\n",
    "    return linreg_data\n",
    "\n",
    "\n",
    "def get_the_mean_of_all_the_columns_in_the_data(linreg_data):\n",
    "    \n",
    "    mean_of_every_column = list(linreg_data.mean(axis = 0))\n",
    "    standard_deviation_of_columns = list(round(linreg_data.std(axis = 0), 2))\n",
    "    \n",
    "    return mean_of_every_column, standard_deviation_of_columns\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def standardize_the_data(linreg_data):\n",
    "    \n",
    "    standardized_linreg_data = pd.DataFrame([])\n",
    "    mean_of_all_columns, standard_deviation_of_all_columns = get_the_mean_of_all_the_columns_in_the_data(linreg_data)\n",
    "    column_names = list(linreg_data.columns.values)\n",
    "    count = 0\n",
    "    \n",
    "    for column_name in column_names:\n",
    "        standardized_linreg_data = linreg_data.apply(lambda column : ((mean_of_all_columns[count] - column)/standard_deviation_of_all_columns[count]), \n",
    "                                                                              axis = 0)\n",
    "        count = count + 1\n",
    "        \n",
    "    \n",
    "    return pd.DataFrame(standardized_linreg_data)\n",
    "    \n",
    "\n",
    " ####################################### QUESTION 3. D ###############################################################\n",
    "\n",
    "'''partitioned data into training set (80%) and test set (20%)'''\n",
    "def split_data_into_features_taret_variables(linreg_data):\n",
    "    input_features = linreg_data.iloc[:,0:len(list(linreg_data.columns.values)) - 1]\n",
    "    target_variable = linreg_data.iloc[:, -1]\n",
    "    \n",
    "    return input_features, target_variable\n",
    "\n",
    "\n",
    "\n",
    "def split_data_into_training_and_test_set(input_features, target_variable, fraction):\n",
    "    no_of_rows_in_entire_set = np.shape(input_features)[0]\n",
    "    \n",
    "    no_of_rows_be_in_training_set = np.ceil(no_of_rows_in_entire_set * fraction)\n",
    "    #no_of_rows_be_in_test_set = no_of_rows_in_entire_set - no_of_rows_be_in_training_set\n",
    "    \n",
    "    train_X = input_features.iloc[:int(no_of_rows_be_in_training_set), ]\n",
    "    test_X = input_features.iloc[int(no_of_rows_be_in_training_set):,]\n",
    "    \n",
    "    train_Y = target_variable.iloc[0 : int(no_of_rows_be_in_training_set)]\n",
    "    test_Y = target_variable.iloc[int(no_of_rows_be_in_training_set) : ]\n",
    "    \n",
    "    return [[train_X, train_Y], [test_X, test_Y]], no_of_rows_be_in_training_set\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def reshape_the_size_of_W(W, to_no_of_columns, to_no_of_rows):\n",
    "    \n",
    "    no_of_rows_in_W, no_of_columns_in_W = np.shape(W)\n",
    "    \n",
    "    no_of_rows_to_be_added_to_W    = to_no_of_rows - no_of_rows_in_W\n",
    "    no_of_columns_to_be_added_to_W = to_no_of_columns - no_of_columns_in_W\n",
    "    \n",
    "    W_row_reshaped = np.zeros((no_of_rows_to_be_added_to_W, 1), dtype=W.dtype)\n",
    "    W = np.concatenate([W, W_row_reshaped])\n",
    "    \n",
    "    return W\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "####################################### QUESTION 3. C ###############################################################\n",
    "\n",
    "'''performed least squares ridge regression with penalty parameter and predicted target variable by finding weights'''\n",
    "def ridge_regression_cost_and_derivative(X, Y, lambda_value, W, no_of_rows_columns_to_be_added_to_W):\n",
    "\n",
    "    temp = (np.dot(X, W) - np.array(Y).reshape(-1, 1))\n",
    "    W_reshaped = reshape_the_size_of_W(W, no_of_rows_columns_to_be_added_to_W, no_of_rows_columns_to_be_added_to_W)\n",
    "    \n",
    "    \n",
    "    '''ridge_reg_cost_func = [(y_i - w * x_i) ^ 2]+ lambda_value * w ^2\n",
    "       partial derivative of ridge_reg_cost_func = 2[((y_i - w * x_i) * x_i.T)) + lambdata_value * w]'''\n",
    "    partial_derivative_of_cost = 2 * ((np.dot(X.T, temp)/ np.shape(Y)[0]) + (lambda_value * W))\n",
    "    \n",
    "    return partial_derivative_of_cost\n",
    "\n",
    "\n",
    "def mylinridgereg(X, Y, lambda_value, no_of_rows_be_in_training_set):\n",
    "    \n",
    "    no_of_columns_in_X = np.shape(X)[1]\n",
    "    \n",
    "    initial_W = np.random.uniform(-1, 1, size= no_of_columns_in_X).reshape(-1, 1)\n",
    "    \n",
    "    final_W = perform_gradient_descent_for_weights(X, Y, lambda_value, initial_W, no_of_rows_be_in_training_set)\n",
    "    \n",
    "    return final_W\n",
    "\n",
    "\n",
    "def mylinridgeregval(X, W):\n",
    "    dot_X_W = np.dot(X, W)\n",
    "    return dot_X_W\n",
    "\n",
    "    \n",
    "def perform_gradient_descent_for_weights(X, Y, lambda_value, W, no_of_rows_be_in_training_set):\n",
    "    learning_rate = 0.001\n",
    "    no_of_iterations = 10\n",
    "    final_weights = W\n",
    "    \n",
    "    for iteration_count in range(no_of_iterations):\n",
    "        \n",
    "        W_from_derivative = ridge_regression_cost_and_derivative(X, Y, lambda_value, \n",
    "                                                                       final_weights, no_of_rows_be_in_training_set)\n",
    "        final_weights = final_weights - (np.multiply(learning_rate, W_from_derivative))\n",
    "    \n",
    "    return final_weights\n",
    "\n",
    "\n",
    "\n",
    "def mean_squared_error(train_Y, predicted_Y):\n",
    "    \n",
    "    error = np.float64(0.0)\n",
    "    len_of_Y = np.shape(predicted_Y)[0]\n",
    "    train_Y = np.array(train_Y).reshape(-1, 1)\n",
    "\n",
    "    for i in range(len_of_Y):\n",
    "        error = error + pow((train_Y[i, 0] - predicted_Y[i, 0]), 2)\n",
    "    \n",
    "    return error/(2 * len_of_Y)\n",
    "                               \n",
    "\n",
    "\n",
    "def find_weights_with_different_lambda_values(train_X, train_Y, test_X, test_Y, no_of_rows_be_in_training_set):\n",
    "    \n",
    "    lambda_values = [value for value in range(0, 10)]\n",
    "\n",
    "    train_Error = []\n",
    "    test_Error = []\n",
    "\n",
    "    min_error_diff_lambda_value = 0\n",
    "    min_test_error = 0\n",
    "    min_error_diff = 1\n",
    "    predicted_train_Y_min_error_diff = np.array([])\n",
    "    predicted_test_Y_min_error_diff = np.array([])\n",
    "    best_weights_for_a_lambda = np.array([])\n",
    "    for iteration in range(0, 10):\n",
    "        \n",
    "        final_weights = mylinridgereg(train_X, train_Y, lambda_values[iteration], no_of_rows_be_in_training_set)\n",
    "        train_predicted_Y = mylinridgeregval(train_X, final_weights)\n",
    "        train_error = mean_squared_error(train_Y, train_predicted_Y)\n",
    "    \n",
    "        \n",
    "        test_predicted_Y = mylinridgeregval(test_X, final_weights)\n",
    "        test_error = mean_squared_error(test_Y, test_predicted_Y)\n",
    "        \n",
    " \n",
    "        train_Error.append(train_error)\n",
    "        test_Error.append(test_error)\n",
    "        \n",
    "#         if min_error_diff > (train_error - test_error) or iteration == 0:\n",
    "#             min_error_diff = (train_error - test_error)\n",
    "#             predicted_train_Y_min_error_diff = train_predicted_Y\n",
    "#             predicted_test_Y_min_error_diff = test_predicted_Y\n",
    "        \n",
    "        if min_test_error > test_error or iteration == 0:\n",
    "            min_error_diff = (train_error - test_error)\n",
    "            predicted_train_Y_min_error_diff = train_predicted_Y\n",
    "            predicted_test_Y_min_error_diff = test_predicted_Y\n",
    "            min_test_error = test_error\n",
    "            min_error_diff_lambda_value = iteration\n",
    "            best_weights_for_a_lambda = final_weights\n",
    "            \n",
    "    best_values_predicted = [min_error_diff_lambda_value, min_error_diff, train_X, train_Y, predicted_train_Y_min_error_diff, \n",
    "                                                             test_X, test_Y, predicted_test_Y_min_error_diff, min_test_error, best_weights_for_a_lambda]\n",
    "    \n",
    "    return best_values_predicted, train_Error, test_Error\n",
    "        \n",
    "\n",
    "####################################### QUESTION 3. E ###############################################################  \n",
    "'''Identify the λ with the best performance and examine the weights of the ridge regression model'''\n",
    "\n",
    "def delete_least_significant_columns_from_data_using_final_weights(final_weights):\n",
    "    \n",
    "    indices_that_would_sort_weights_list = np.argsort(np.array(final_weights))\n",
    "    indices_of_least_significant_weights = indices_that_would_sort_weights_list[3:6]\n",
    "    \n",
    "    return indices_of_least_significant_weights\n",
    "\n",
    "\n",
    "def remove_least_weighted_columns_from_the_data(train_X, test_X, indices_of_top_3_minimum_weights):\n",
    "    train_X.drop(indices_of_top_3_minimum_weights, axis = 1, inplace = True)\n",
    "    test_X.drop(indices_of_top_3_minimum_weights, axis = 1, inplace = True)\n",
    "    \n",
    "    return train_X, test_X\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "####################################### QUESTION 3. F ###############################################################\n",
    "\n",
    "'''plotting a graph between different lambda_values and corresponding MSE for both train_data and test_data'''\n",
    "\n",
    "def plot_graph_for_lambda_and_errors(fraction_values, lambda_values, train_errors, test_errors):\n",
    "    \n",
    "    count = 0\n",
    "    for fraction in fraction_values:\n",
    "        train_error = train_errors[count]\n",
    "        test_error = test_errors[count]\n",
    "    \n",
    "        plot_MSE(fraction, train_error, lambda_values, True)\n",
    "        plot_MSE(fraction, test_error, lambda_values, False)\n",
    "        count = count + 1\n",
    "    \n",
    "\n",
    "def plot_MSE(fraction, error, lambda_values, is_train_error):\n",
    "    plt.plot(lambda_values, error) \n",
    "    # naming the x axis \n",
    "    plt.xlabel('lambda_values') \n",
    "    # naming the y axis \n",
    "    if is_train_error:\n",
    "        plt.ylabel('train_MSE') \n",
    "        plt.savefig(str(fraction * 100) + '_TrMSE' + '.png')\n",
    "    else:\n",
    "        plt.ylabel('test_MSE')\n",
    "        plt.savefig(str(fraction * 100) + '_TsMSE' + '.png')\n",
    "\n",
    "    # giving a title to my graph \n",
    "    plt.title(str(fraction * 100) + ' training set ' + str(np.ceil((1 - fraction) * 100)) + ' test_set') \n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "\n",
    "####################################### QUESTION 3. H ###############################################################\n",
    "\n",
    "'''plotting graph between actual and predicted target values for both training and test set for various partitions'''   \n",
    "def plot_graph_for_actual_and_predicted_values(best_values, fraction_values):\n",
    "    \n",
    "    for fraction_value, best_values_list in best_values.items():\n",
    "\n",
    "        lambda_value = best_values_list[0]\n",
    "        predicted_train_Y = best_values_list[4]\n",
    "        actual_train_Y = best_values_list[3]\n",
    "        \n",
    "        predicted_test_Y = best_values_list[7]\n",
    "        actual_test_Y = best_values_list[6]\n",
    "        \n",
    "        plot_actual_VS_predicted_values(fraction_value, actual_train_Y, predicted_train_Y, lambda_value, True)\n",
    "        plot_actual_VS_predicted_values(fraction_value, actual_test_Y, predicted_test_Y, lambda_value, False)\n",
    "        \n",
    "\n",
    "def plot_actual_VS_predicted_values(fraction, actual, predicted, value, are_training_values):\n",
    "   \n",
    "    plt.plot(predicted, actual.tolist(), marker = 'o') \n",
    "    # naming the x axis \n",
    "    plt.xlabel('predicted') \n",
    "    plt.ylabel('actual') \n",
    "    # naming the y axis \n",
    "    if are_training_values:\n",
    "        plt.title('training_set_predicted_VS_actual') \n",
    "        plt.savefig('lambda_' +str(value) + '_training_set' + '.png')\n",
    "    else:\n",
    "        plt.title('test_set_predicted_VS_actual') \n",
    "        plt.savefig('lambda_' +str(value) + '_test_set' + '.png')\n",
    "\n",
    "    plt.show() \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "####################################### QUESTION 3. G ###############################################################\n",
    "\n",
    "def plot_graph_between_min_MSE_fraction_and_lambda_value(best_values_dict):\n",
    "    data_partition_fraction_list = []\n",
    "    lambda_values_list = []\n",
    "    min_test_error_list = []\n",
    "    for fraction_value, best_values_list in best_values_dict.items():\n",
    "        data_partition_fraction_list.append(fraction_value)\n",
    "        lambda_values_list.append(best_values_list[0])\n",
    "        min_test_error_list.append(best_values_list[8])\n",
    "        \n",
    "    plot_min_MSE_fraction_lambda(min_test_error_list, lambda_values_list, True)\n",
    "    plot_min_MSE_fraction_lambda(min_test_error_list, data_partition_fraction_list, False)\n",
    "        \n",
    "\n",
    "def plot_min_MSE_fraction_lambda(min_test_error, value, is_lambda_value):\n",
    "   \n",
    "    plt.plot(value, min_test_error, marker = 'o') \n",
    "    # naming the x axis \n",
    "    if is_lambda_value:\n",
    "        plt.xlabel('lambda_value') \n",
    "    plt.ylabel('min_test_error') \n",
    "    # naming the y axis \n",
    "    if is_lambda_value:\n",
    "        plt.title('lambda_VS_min_MSE') \n",
    "        plt.savefig('lambda_'+ 'MSE' + '.png')\n",
    "    else:\n",
    "        plt.title('partition_fraction_VS_MSE') \n",
    "        plt.savefig('fraction'  + 'MSE' + '.png')\n",
    "\n",
    "    plt.show() \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "################## Question 3. a\n",
    "\n",
    "linreg_data_list = read_the_data()\n",
    "binary_values = get_a_df_with_binary_values_corresponding_to_gender(linreg_data_list)\n",
    "linreg_df = replace_gender_in_linreg_with_binary_values(binary_values, linreg_data_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## Question 3. b\n",
    "\n",
    "linreg_df = convert_data_type_from_str_to_float(linreg_df)\n",
    "input_features, target_variable = split_data_into_features_taret_variables(linreg_df)\n",
    "del(linreg_df)\n",
    "del(binary_values)\n",
    "train_data_standardized = standardize_the_data(input_features)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## Question 3. d\n",
    "\n",
    "training_test_set, no_of_rows_be_in_training_set = split_data_into_training_and_test_set(train_data_standardized, target_variable, 0.8)\n",
    "train_X, train_Y = training_test_set[0]\n",
    "test_X, test_Y = training_test_set[1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## Question 3. c\n",
    "\n",
    "best_values_predicted, train_Error, test_Error = find_weights_with_different_lambda_values(train_X, \n",
    "                                                                        train_Y, test_X, test_Y, int(no_of_rows_be_in_training_set))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/tensorflow-session/lib/python3.6/site-packages/pandas/core/frame.py:3940: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "################## Question 3. e\n",
    "'''best_values_predicted = [min_error_diff_lambda_value, min_error_diff, train_X, train_Y, \n",
    "                            predicted_train_Y_min_error_diff, test_X, test_Y, \n",
    "                            predicted_test_Y_min_error_diff, min_test_error]'''\n",
    "\n",
    "#min_difference_error = min(best_values_predicted[8]\n",
    "#index_of_min_difference_error  = error_Difference.index(min_difference_error)\n",
    "\n",
    "weights_corresponding_min_test_error = best_values_predicted[9]\n",
    "\n",
    "weights_list = [value[0] for value in weights_corresponding_min_test_error.tolist()]\n",
    "\n",
    "\n",
    "indices_of_least_significant_columns = delete_least_significant_columns_from_data_using_final_weights(weights_list)\n",
    "\n",
    "train_X_copy, test_X_copy = train_X, test_X\n",
    "\n",
    "train_X_trimmed, test_X_trimmed = remove_least_weighted_columns_from_the_data(train_X_copy, \n",
    "                                                                              test_X_copy, indices_of_least_significant_columns)\n",
    "\n",
    "best_values_predicted_t, train_Error_t, test_Error_t = find_weights_with_different_lambda_values(train_X_trimmed, \n",
    "                                                                    train_Y, test_X_trimmed, test_Y, int(no_of_rows_be_in_training_set))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################## question 3. g\n",
    "\n",
    "plot_graph_between_min_MSE_fraction_and_lambda_value(best_values)\n",
    "\n",
    "\n",
    "######################## question 3. h\n",
    "\n",
    "plot_graph_for_actual_and_predicted_values(best_values, fraction_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################## question 3. f\n",
    "\n",
    "fraction_values = [0.5, 0.6, 0.75, 0.8, 0.9]\n",
    "lambda_values_fraction = [value for value in range(0, 10)]\n",
    "#final_Weights_fraction = []\n",
    "train_Error_fraction = []\n",
    "test_Error_fraction = []\n",
    "best_values = {}\n",
    "\n",
    "for fraction_value in fraction_values:\n",
    "    training_test_set, no_of_rows_be_in_training_set = split_data_into_training_and_test_set(train_data_standardized, \n",
    "                                                                                             target_variable, fraction_value)\n",
    "    train_X, train_Y = training_test_set[0]\n",
    "    test_X, test_Y = training_test_set[1]\n",
    "    \n",
    "    best_values_predicted, train_Error, test_Error = find_weights_with_different_lambda_values(train_X, \n",
    "                                                                        train_Y, test_X, test_Y, int(no_of_rows_be_in_training_set))\n",
    "\n",
    "    \n",
    "    #final_Weights_fraction.append(final_Weights)\n",
    "    train_Error_fraction.append(train_Error)\n",
    "    test_Error_fraction.append(test_Error)\n",
    "    best_values[fraction_value] = best_values_predicted\n",
    "    \n",
    "    \n",
    "\n",
    "plot_graph_for_lambda_and_errors(fraction_values, lambda_values_fraction, train_Error_fraction, test_Error_fraction)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
